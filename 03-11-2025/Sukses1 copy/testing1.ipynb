{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a12eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Memuat Tokenizer dan Model 'Qwen/Qwen3-Embedding-0.6B'...\n",
      "  > Model dan Tokenizer berhasil dimuat.\n",
      "\n",
      "Contoh Kalimat: Kasih itu sabar;\n",
      "Dimensi Embedding: 1024\n",
      "Contoh Embedding (5 elemen pertama): [-0.04304343  0.04892129 -0.012476    0.03305931  0.0044877 ]\n",
      "\n",
      "Contoh Query: Apa itu kasih?\n",
      "Dimensi Embedding Query: 1024\n",
      "Contoh Embedding Query (5 elemen pertama): [-0.03473022 -0.05707059 -0.01321422  0.01108161  0.00415797]\n"
     ]
    }
   ],
   "source": [
    "# File: custom_embedder.py (atau tambahkan ke utils.py)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class QwenEmbedder:\n",
    "    \"\"\"\n",
    "    Kelas kustom untuk membuat embedding teks menggunakan model Qwen dari Hugging Face,\n",
    "    mengimplementasikan proses secara manual tanpa wrapper LangChain.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str, device: str = 'cpu'):\n",
    "        \"\"\"\n",
    "        Menginisialisasi tokenizer dan model.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Nama model di Hugging Face Hub (cth: 'Qwen/Qwen3-Embedding-0.6B').\n",
    "            device (str): Perangkat untuk menjalankan model ('cpu' atau 'cuda').\n",
    "        \"\"\"\n",
    "        print(f\"  > Memuat Tokenizer dan Model '{model_name}'...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Pindahkan model ke perangkat yang dipilih (CPU atau GPU)\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval() # Set model ke mode evaluasi (penting untuk inference)\n",
    "        print(\"  > Model dan Tokenizer berhasil dimuat.\")\n",
    "\n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Melakukan Mean Pooling.\n",
    "        Mengambil output dari model dan attention mask untuk menghasilkan satu vektor\n",
    "        yang merepresentasikan seluruh kalimat.\n",
    "        \"\"\"\n",
    "        # Langkah 1: Dapatkan semua embedding token dari output model\n",
    "        token_embeddings = model_output.last_hidden_state\n",
    "        \n",
    "        # Langkah 2: Buat attention mask yang diperluas agar ukurannya cocok dengan token_embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        \n",
    "        # Langkah 3: Kalikan embedding dengan mask untuk menolkan embedding dari token padding\n",
    "        masked_embeddings = token_embeddings * input_mask_expanded\n",
    "        \n",
    "        # Langkah 4: Jumlahkan embedding yang relevan dan bagi dengan jumlah token yang relevan\n",
    "        sum_embeddings = torch.sum(masked_embeddings, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        \n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Membuat embedding untuk sekumpulan dokumen (teks).\n",
    "\n",
    "        Args:\n",
    "            texts (List[str]): Daftar string teks yang akan di-embed.\n",
    "\n",
    "        Returns:\n",
    "            List[List[float]]: Daftar dari embedding, di mana setiap embedding adalah daftar float.\n",
    "        \"\"\"\n",
    "        if not texts or not isinstance(texts, list):\n",
    "            return []\n",
    "            \n",
    "        # 1. TOKENISASI\n",
    "        # Mengubah teks menjadi format yang bisa dibaca model (Token ID).\n",
    "        # padding=True -> Menyamakan panjang semua kalimat dalam batch.\n",
    "        # truncation=True -> Memotong kalimat yang terlalu panjang.\n",
    "        # return_tensors='pt' -> Mengembalikan hasil sebagai PyTorch Tensors.\n",
    "        encoded_input = self.tokenizer(\n",
    "            texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt',\n",
    "            max_length=1024 # Batas panjang token, bisa disesuaikan\n",
    "        )\n",
    "        \n",
    "        # Pindahkan data token ke perangkat yang sama dengan model\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "\n",
    "        # 2. INFERENCE MODEL\n",
    "        # Matikan perhitungan gradien untuk mempercepat proses dan menghemat memori.\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "\n",
    "        # 3. POOLING\n",
    "        # Mengubah output per-token menjadi satu vektor per-kalimat.\n",
    "        sentence_embeddings = self._mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "        # 4. NORMALISASI\n",
    "        # Menormalkan vektor agar panjangnya (magnitude) menjadi 1.\n",
    "        # Ini penting untuk perhitungan cosine similarity.\n",
    "        normalized_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Pindahkan hasil kembali ke CPU dan ubah menjadi list Python biasa\n",
    "        return normalized_embeddings.cpu().numpy().tolist()\n",
    "\n",
    "    def embed_query(self, query: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Membuat embedding untuk satu teks (pertanyaan).\n",
    "\n",
    "        Args:\n",
    "            query (str): String pertanyaan.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: Embedding untuk pertanyaan tersebut.\n",
    "        \"\"\"\n",
    "        # Prosesnya sama, hanya saja inputnya adalah list dengan satu elemen.\n",
    "        # [0] di akhir untuk mengambil embedding tunggal dari hasil list.\n",
    "        return self.embed_documents([query])[0]\n",
    "\n",
    "\n",
    "# --- CONTOH PENGGUNAAN ---\n",
    "if __name__ == '__main__':\n",
    "    # Inisialisasi embedder kita\n",
    "    embedder = QwenEmbedder(model_name=\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "    \n",
    "    # Daftar kalimat untuk di-embed\n",
    "    kalimat = [\n",
    "        \"Kasih itu sabar;\",\n",
    "        \"Kasih itu murah hati;\",\n",
    "        \"Ia tidak cemburu.\",\n",
    "        \"Apa definisi dari kasih?\"\n",
    "    ]\n",
    "    \n",
    "    # Dapatkan embeddings\n",
    "    embeddings = embedder.embed_documents(kalimat)\n",
    "    \n",
    "    # Tampilkan hasil embedding untuk kalimat pertama\n",
    "    print(\"\\nContoh Kalimat:\", kalimat[0])\n",
    "    print(\"Dimensi Embedding:\", len(embeddings[0]))\n",
    "    print(\"Contoh Embedding (5 elemen pertama):\", np.array(embeddings[0][:5]))\n",
    "    \n",
    "    # Contoh embed satu query\n",
    "    query_embedding = embedder.embed_query(\"Apa itu kasih?\")\n",
    "    print(\"\\nContoh Query:\", \"Apa itu kasih?\")\n",
    "    print(\"Dimensi Embedding Query:\", len(query_embedding))\n",
    "    print(\"Contoh Embedding Query (5 elemen pertama):\", np.array(query_embedding[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fa4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mobil:\n",
    "    def __init__(self, merk, warna):\n",
    "        self.merk = merk\n",
    "        self.warna = warna\n",
    "\n",
    "    def jalan(self):\n",
    "        print(f\"Mobil {self.merk} berwarna {self.warna} sedang berjalan!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7164fa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobil Toyota berwarna merah sedang berjalan!\n",
      "Mobil Honda berwarna biru sedang berjalan!\n"
     ]
    }
   ],
   "source": [
    "mobil1 = Mobil(\"Toyota\", \"merah\")\n",
    "mobil2 = Mobil(\"Honda\", \"biru\")\n",
    "\n",
    "mobil1.jalan()\n",
    "mobil2.jalan()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503097a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tambah(a,b):\n",
    "    hasil_tambah=a+b\n",
    "    return hasil_tambah\n",
    "\n",
    "def perkalian(c,d):\n",
    "    hasil_perkalian=c*d\n",
    "    return hasil_perkalian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c977e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ini adakah hasil pertambahan 12\n"
     ]
    }
   ],
   "source": [
    "pertambahan=tambah(5,7)\n",
    "print(f\"ini adakah hasil pertambahan {pertambahan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8abc11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perkalian(a,b):\n",
    "    hasil_perkalian=a*b\n",
    "    print(\"hasil_perkalian\", hasil_perkalian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb55c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil_perkalian 14\n"
     ]
    }
   ],
   "source": [
    "perkalian(2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f546a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matematika:\n",
    "    def tambah(a,b):\n",
    "        hasil_tambah=a+b\n",
    "        return hasil_tambah\n",
    "\n",
    "    def perkalian(c,d):\n",
    "        hasil_perkalian=c*d\n",
    "        return hasil_perkalian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "math=matematika\n",
    "pertambahan=math.tambah(5,7)\n",
    "print(pertambahan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7161e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matematikaself:\n",
    "    def __init__(self,a,b):\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "\n",
    "    def pertambahan(self):\n",
    "        hasil_tambah=self.a+self.b\n",
    "        return hasil_tambah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23032785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "math=matematikaself(5,7)\n",
    "pertambahan=math.pertambahan()\n",
    "print(pertambahan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfb2a559",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2605420543.py, line 68)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m# print(\"Contoh Embedding Query (5 elemen pertama):\", np.array(query_embedding[:5]))\u001b[39m\n                                                                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# File: custom_embedder.py (atau tambahkan ke utils.py)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class QwenEmbedder:\n",
    "    def __init__(self, model_name: str, device: str = 'cpu'):\n",
    "        print(f\"  > Memuat Tokenizer dan Model '{model_name}'...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval() \n",
    "        print(\"  > Model dan Tokenizer berhasil dimuat.\")\n",
    "\n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        masked_embeddings = token_embeddings * input_mask_expanded\n",
    "        sum_embeddings = torch.sum(masked_embeddings, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        if not texts or not isinstance(texts, list):\n",
    "            return []\n",
    "        encoded_input = self.tokenizer(\n",
    "            texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt',\n",
    "            max_length=1024 \n",
    "        )\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "        sentence_embeddings = self._mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        normalized_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return normalized_embeddings.cpu().numpy().tolist()\n",
    "\n",
    "    def embed_query(self, query: str) -> List[float]:\n",
    "        return self.embed_documents([query])[0]\n",
    "if __name__ == '__main__':\n",
    "    # embedder = QwenEmbedder(model_name=\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "    \n",
    "    # # Daftar kalimat untuk di-embed\n",
    "    # kalimat = [\n",
    "    #     \"Kasih itu sabar;\",\n",
    "    #     \"Kasih itu murah hati;\",\n",
    "    #     \"Ia tidak cemburu.\",\n",
    "    #     \"Apa definisi dari kasih?\"\n",
    "    # ]\n",
    "    \n",
    "    # # Dapatkan embeddings\n",
    "    # embeddings = embedder.embed_documents(kalimat)\n",
    "    \n",
    "    # # Tampilkan hasil embedding untuk kalimat pertama\n",
    "    # print(\"\\nContoh Kalimat:\", kalimat[0])\n",
    "    # print(\"Dimensi Embedding:\", len(embeddings[0]))\n",
    "    # print(\"Contoh Embedding (5 elemen pertama):\", np.array(embeddings[0][:5]))\n",
    "    \n",
    "    # # Contoh embed satu query\n",
    "    # query_embedding = embedder.embed_query(\"Apa itu kasih?\")\n",
    "    # print(\"\\nContoh Query:\", \"Apa itu kasih?\")\n",
    "    # print(\"Dimensi Embedding Query:\", len(query_embedding))\n",
    "    # print(\"Contoh Embedding Query (5 elemen pertama):\", np.array(query_embedding[:5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
